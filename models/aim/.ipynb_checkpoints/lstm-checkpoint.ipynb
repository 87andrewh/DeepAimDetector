{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_uuid": "d6fb32fd69316596e236eab5fb8cf77c848508c3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Bidirectional\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f674695f1742479cefdeec0e81ab469f7b6ec90f"
   },
   "source": [
    "### Load the data into Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "_uuid": "aca2f1d9da3f35d104763166fe4d25448410d8f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>663</th>\n",
       "      <th>664</th>\n",
       "      <th>665</th>\n",
       "      <th>666</th>\n",
       "      <th>667</th>\n",
       "      <th>668</th>\n",
       "      <th>669</th>\n",
       "      <th>670</th>\n",
       "      <th>671</th>\n",
       "      <th>672</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>70.349</td>\n",
       "      <td>0.652</td>\n",
       "      <td>867</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>775</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-156.418</td>\n",
       "      <td>-92.538</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>0.066</td>\n",
       "      <td>-28.703</td>\n",
       "      <td>0.626</td>\n",
       "      <td>525</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.099</td>\n",
       "      <td>...</td>\n",
       "      <td>1705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.461</td>\n",
       "      <td>-27.112</td>\n",
       "      <td>-0.605</td>\n",
       "      <td>1705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.890</td>\n",
       "      <td>-0.758</td>\n",
       "      <td>32.375</td>\n",
       "      <td>-9.009</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>-2.834</td>\n",
       "      <td>-1.620</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.564</td>\n",
       "      <td>0.010</td>\n",
       "      <td>297</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.033</td>\n",
       "      <td>28.397</td>\n",
       "      <td>-2.074</td>\n",
       "      <td>1999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>11.646</td>\n",
       "      <td>0.494</td>\n",
       "      <td>11.703</td>\n",
       "      <td>-2.944</td>\n",
       "      <td>1340</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.428</td>\n",
       "      <td>...</td>\n",
       "      <td>332</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.641</td>\n",
       "      <td>1.749</td>\n",
       "      <td>328</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 673 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0       1      2       3      4     5    6    7      8      9    ...   663  \\\n",
       "0    1   0.000  0.000  70.349  0.652   867    0  100  0.000  0.000  ...   775   \n",
       "1    1  -0.198  0.066 -28.703  0.626   525    0  100 -0.170  0.099  ...  1705   \n",
       "2    1   0.890 -0.758  32.375 -9.009   560    0  100 -2.834 -1.620  ...     0   \n",
       "3    1   0.000  0.000  -0.564  0.010   297    0  100 -0.033  0.000  ...  2003   \n",
       "4    1  11.646  0.494  11.703 -2.944  1340    0   26  0.104  0.428  ...   332   \n",
       "\n",
       "   664  665      666     667     668    669   670  671  672  \n",
       "0    0    0 -156.418 -92.538   0.000  0.000     0    0    0  \n",
       "1    0    0    0.659   0.461 -27.112 -0.605  1705    0    0  \n",
       "2    0    0    0.000   0.000   0.000  0.000     0    0    0  \n",
       "3    0    0    0.000   0.033  28.397 -2.074  1999    0    0  \n",
       "4    0    0    0.000   0.000  18.641  1.749   328    0    0  \n",
       "\n",
       "[5 rows x 673 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('aim.csv', header=None, delimiter=',',encoding='latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AHuang\\Anaconda3\\envs\\keras\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Number of clean and cheat samples')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df[0])\n",
    "plt.xlabel('Cheating')\n",
    "plt.title('Number of clean and cheat samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.89  -0.758 32.375 -9.009  0.   ]\n",
      " [-2.834 -1.62  35.4   -7.388  0.   ]\n",
      " [-3.895 -1.549 39.504 -5.839  0.   ]\n",
      " [-2.214 -0.956 41.933 -4.883  0.   ]\n",
      " [-1.879 -0.731 44.034 -4.153  0.   ]\n",
      " [-1.681 -0.527 45.95  -3.625  0.   ]\n",
      " [-3.367 -0.626 49.561 -2.999  0.   ]\n",
      " [-1.851 -0.494 51.689 -2.505  0.   ]\n",
      " [-0.791 -0.33  52.759 -2.175  0.   ]\n",
      " [-1.516 -0.428 54.554 -1.747  0.   ]\n",
      " [-2.148 -0.396 56.996 -1.351  0.   ]\n",
      " [-3.197 -0.099 60.549 -1.252  0.   ]\n",
      " [-1.258  0.099 62.278 -1.351  1.   ]\n",
      " [ 2.247  0.    60.583 -1.351  0.   ]\n",
      " [ 0.857  0.066 60.35  -1.417  0.   ]]\n"
     ]
    }
   ],
   "source": [
    "data = df.to_numpy()\n",
    "# Only us delta yaw and delta pitch features\n",
    "features = [0, 1, 2, 3, 5]\n",
    "num_features = len(features)\n",
    "idxs = []\n",
    "for i in range(data.shape[1] - 1):\n",
    "    if (i % 7) in features:\n",
    "        idxs.append(i + 1)\n",
    "\n",
    "X = data[:, idxs]\n",
    "X = X.reshape(-1, num_samples, num_features)\n",
    "Y = data[:, 0]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.15)\n",
    "print(X[2][:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some statistics\n",
    "#killerDeltaYaws = []\n",
    "#for i in range(X.shape[0]):\n",
    "#    for j in range(X.shape[1]):\n",
    "#        if (not np.isclose(X[i][j][0], 0)):\n",
    "#            killerDeltaYaws.append(X[i][j][0])\n",
    "#        \n",
    "#killerDeltaPitches = []\n",
    "#for i in range(X.shape[0]):\n",
    "#    for j in range(X.shape[1]):\n",
    "#        if (not np.isclose(X[i][j][1], 0)):\n",
    "#            killerDeltaPitches.append(X[i][j][1])\n",
    "#            \n",
    "#plt.hist(killerDeltaYaws, bins = np.linspace(-2, 2, 40)) \n",
    "#plt.title(\"Delta yaw histogram\") \n",
    "#plt.show()\n",
    "#\n",
    "#plt.hist(killerDeltaPitches, bins = np.linspace(-2, 2, 40)) \n",
    "#plt.title(\"Delta pitch histogram\") \n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "_uuid": "78fff25b8be1de575bff071a2027f3dd2b11b911"
   },
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[num_samples, num_features])\n",
    "    \n",
    "    layer = LSTM(512)(inputs)\n",
    "    #layer = Bidirectional(LSTM(128, return_sequences=False))(inputs)\n",
    "    #layer = Bidirectional(LSTM(128))(layer)\n",
    "    \n",
    "    layer = Dense(512, name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1, name='out')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "_uuid": "a0ede32d4127e8b4990fd74fe97fadef9e565d17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 96, 5)             0         \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 256)               268288    \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 334,337\n",
      "Trainable params: 334,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "model.summary()\n",
    "opt = RMSprop(learning_rate=6e-4)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "_uuid": "98f6d6318352420ea49c532cda158f715f940f4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1654 samples, validate on 414 samples\n",
      "Epoch 1/200\n",
      "1654/1654 [==============================] - 1s 385us/step - loss: 0.7580 - accuracy: 0.5000 - val_loss: 0.6941 - val_accuracy: 0.5024\n",
      "Epoch 2/200\n",
      "1654/1654 [==============================] - 0s 169us/step - loss: 0.7027 - accuracy: 0.5363 - val_loss: 0.7006 - val_accuracy: 0.5362\n",
      "Epoch 3/200\n",
      "1654/1654 [==============================] - 0s 155us/step - loss: 0.6880 - accuracy: 0.5502 - val_loss: 0.7112 - val_accuracy: 0.5314\n",
      "Epoch 4/200\n",
      "1654/1654 [==============================] - 0s 171us/step - loss: 0.6834 - accuracy: 0.5738 - val_loss: 0.7037 - val_accuracy: 0.4903\n",
      "Epoch 5/200\n",
      "1654/1654 [==============================] - 0s 157us/step - loss: 0.6842 - accuracy: 0.5641 - val_loss: 0.6971 - val_accuracy: 0.5435\n",
      "Epoch 6/200\n",
      "1654/1654 [==============================] - 0s 156us/step - loss: 0.6656 - accuracy: 0.5840 - val_loss: 0.6970 - val_accuracy: 0.5773\n",
      "Epoch 7/200\n",
      "1654/1654 [==============================] - 0s 168us/step - loss: 0.6761 - accuracy: 0.5804 - val_loss: 0.6889 - val_accuracy: 0.5725\n",
      "Epoch 8/200\n",
      "1654/1654 [==============================] - 0s 165us/step - loss: 0.6607 - accuracy: 0.6004 - val_loss: 0.6869 - val_accuracy: 0.5604\n",
      "Epoch 9/200\n",
      "1654/1654 [==============================] - 0s 162us/step - loss: 0.6583 - accuracy: 0.6052 - val_loss: 0.7008 - val_accuracy: 0.5483\n",
      "Epoch 10/200\n",
      "1654/1654 [==============================] - 0s 163us/step - loss: 0.6571 - accuracy: 0.6100 - val_loss: 0.7019 - val_accuracy: 0.5483\n",
      "Epoch 11/200\n",
      "1654/1654 [==============================] - 0s 175us/step - loss: 0.6591 - accuracy: 0.6010 - val_loss: 0.6910 - val_accuracy: 0.5845\n",
      "Epoch 12/200\n",
      "1654/1654 [==============================] - 0s 166us/step - loss: 0.6542 - accuracy: 0.6155 - val_loss: 0.7040 - val_accuracy: 0.5483\n",
      "Epoch 13/200\n",
      "1654/1654 [==============================] - 0s 163us/step - loss: 0.6539 - accuracy: 0.6058 - val_loss: 0.7036 - val_accuracy: 0.5531\n",
      "Epoch 14/200\n",
      "1654/1654 [==============================] - 0s 170us/step - loss: 0.6383 - accuracy: 0.6421 - val_loss: 0.7065 - val_accuracy: 0.5580\n",
      "Epoch 15/200\n",
      "1654/1654 [==============================] - 0s 165us/step - loss: 0.6360 - accuracy: 0.6463 - val_loss: 0.6905 - val_accuracy: 0.5700\n",
      "Epoch 16/200\n",
      "1654/1654 [==============================] - 0s 160us/step - loss: 0.6308 - accuracy: 0.6378 - val_loss: 0.6945 - val_accuracy: 0.5604\n",
      "Epoch 17/200\n",
      "1654/1654 [==============================] - 0s 165us/step - loss: 0.6267 - accuracy: 0.6451 - val_loss: 0.7103 - val_accuracy: 0.5797\n",
      "Epoch 18/200\n",
      "1654/1654 [==============================] - 0s 162us/step - loss: 0.6294 - accuracy: 0.6409 - val_loss: 0.7090 - val_accuracy: 0.5604\n",
      "Epoch 19/200\n",
      "1654/1654 [==============================] - 0s 156us/step - loss: 0.6162 - accuracy: 0.6584 - val_loss: 0.6967 - val_accuracy: 0.5531\n",
      "Epoch 20/200\n",
      "1654/1654 [==============================] - 0s 157us/step - loss: 0.6115 - accuracy: 0.6578 - val_loss: 0.6982 - val_accuracy: 0.5749\n",
      "Epoch 21/200\n",
      "1654/1654 [==============================] - 0s 159us/step - loss: 0.6025 - accuracy: 0.6723 - val_loss: 0.7109 - val_accuracy: 0.5821\n",
      "Epoch 22/200\n",
      "1654/1654 [==============================] - 0s 159us/step - loss: 0.6035 - accuracy: 0.6771 - val_loss: 0.7133 - val_accuracy: 0.5725\n",
      "Epoch 23/200\n",
      "1654/1654 [==============================] - 0s 159us/step - loss: 0.6001 - accuracy: 0.6699 - val_loss: 0.7097 - val_accuracy: 0.5700\n",
      "Epoch 24/200\n",
      "1654/1654 [==============================] - 0s 159us/step - loss: 0.5940 - accuracy: 0.6669 - val_loss: 0.7332 - val_accuracy: 0.5483\n",
      "Epoch 25/200\n",
      "1654/1654 [==============================] - 0s 157us/step - loss: 0.5990 - accuracy: 0.6651 - val_loss: 0.7053 - val_accuracy: 0.5604\n",
      "Epoch 26/200\n",
      "1654/1654 [==============================] - 0s 157us/step - loss: 0.5857 - accuracy: 0.6911 - val_loss: 0.7054 - val_accuracy: 0.5942\n",
      "Epoch 27/200\n",
      "1654/1654 [==============================] - 0s 158us/step - loss: 0.5800 - accuracy: 0.6953 - val_loss: 0.7307 - val_accuracy: 0.5652\n",
      "Epoch 28/200\n",
      "1654/1654 [==============================] - 0s 179us/step - loss: 0.5735 - accuracy: 0.6947 - val_loss: 0.7026 - val_accuracy: 0.5990\n",
      "Epoch 29/200\n",
      "1654/1654 [==============================] - 0s 162us/step - loss: 0.5646 - accuracy: 0.7134 - val_loss: 0.7085 - val_accuracy: 0.5870\n",
      "Epoch 30/200\n",
      "1654/1654 [==============================] - 0s 162us/step - loss: 0.5654 - accuracy: 0.7062 - val_loss: 0.7373 - val_accuracy: 0.5725\n",
      "Epoch 31/200\n",
      "1654/1654 [==============================] - 0s 166us/step - loss: 0.5752 - accuracy: 0.6941 - val_loss: 0.7234 - val_accuracy: 0.6087\n",
      "Epoch 32/200\n",
      "1654/1654 [==============================] - 0s 156us/step - loss: 0.5547 - accuracy: 0.7050 - val_loss: 0.7269 - val_accuracy: 0.5870\n",
      "Epoch 33/200\n",
      "1654/1654 [==============================] - 0s 155us/step - loss: 0.5509 - accuracy: 0.7243 - val_loss: 0.7564 - val_accuracy: 0.5652\n",
      "Epoch 34/200\n",
      "1654/1654 [==============================] - 0s 154us/step - loss: 0.5479 - accuracy: 0.7164 - val_loss: 0.7258 - val_accuracy: 0.5966\n",
      "Epoch 35/200\n",
      "1654/1654 [==============================] - 0s 157us/step - loss: 0.5316 - accuracy: 0.7340 - val_loss: 0.7405 - val_accuracy: 0.6014\n",
      "Epoch 36/200\n",
      "1654/1654 [==============================] - 0s 156us/step - loss: 0.5331 - accuracy: 0.7261 - val_loss: 0.7555 - val_accuracy: 0.5749\n",
      "Epoch 37/200\n",
      "1654/1654 [==============================] - 0s 156us/step - loss: 0.5176 - accuracy: 0.7364 - val_loss: 0.7379 - val_accuracy: 0.5797\n",
      "Epoch 38/200\n",
      "1654/1654 [==============================] - 0s 165us/step - loss: 0.5584 - accuracy: 0.7080 - val_loss: 0.7579 - val_accuracy: 0.5725\n",
      "Epoch 39/200\n",
      "1654/1654 [==============================] - 0s 169us/step - loss: 0.5285 - accuracy: 0.7297 - val_loss: 0.7617 - val_accuracy: 0.5411\n",
      "Epoch 40/200\n",
      "1654/1654 [==============================] - 0s 169us/step - loss: 0.5180 - accuracy: 0.7406 - val_loss: 0.7786 - val_accuracy: 0.5459\n",
      "Epoch 41/200\n",
      "1654/1654 [==============================] - 0s 166us/step - loss: 0.5177 - accuracy: 0.7406 - val_loss: 0.7924 - val_accuracy: 0.5652\n",
      "Epoch 42/200\n",
      "1654/1654 [==============================] - 0s 169us/step - loss: 0.5399 - accuracy: 0.7134 - val_loss: 0.7576 - val_accuracy: 0.5556\n",
      "Epoch 43/200\n",
      "1654/1654 [==============================] - 0s 162us/step - loss: 0.5051 - accuracy: 0.7449 - val_loss: 0.7597 - val_accuracy: 0.5918\n",
      "Epoch 44/200\n",
      "1654/1654 [==============================] - 0s 162us/step - loss: 0.5005 - accuracy: 0.7467 - val_loss: 0.7621 - val_accuracy: 0.5821\n",
      "Epoch 45/200\n",
      "1654/1654 [==============================] - 0s 173us/step - loss: 0.5000 - accuracy: 0.7551 - val_loss: 0.7653 - val_accuracy: 0.5942\n",
      "Epoch 46/200\n",
      "1654/1654 [==============================] - 0s 157us/step - loss: 0.4990 - accuracy: 0.7509 - val_loss: 0.7747 - val_accuracy: 0.5894\n",
      "Epoch 47/200\n",
      "1654/1654 [==============================] - 0s 172us/step - loss: 0.4909 - accuracy: 0.7678 - val_loss: 0.8300 - val_accuracy: 0.5797\n",
      "Epoch 48/200\n",
      "1654/1654 [==============================] - 0s 174us/step - loss: 0.4782 - accuracy: 0.7733 - val_loss: 0.7835 - val_accuracy: 0.5845\n",
      "Epoch 49/200\n",
      "1654/1654 [==============================] - 0s 163us/step - loss: 0.4797 - accuracy: 0.7642 - val_loss: 0.7919 - val_accuracy: 0.5773\n",
      "Epoch 50/200\n",
      "1654/1654 [==============================] - 0s 163us/step - loss: 0.5001 - accuracy: 0.7570 - val_loss: 0.8329 - val_accuracy: 0.5797\n",
      "Epoch 51/200\n",
      "1654/1654 [==============================] - 0s 169us/step - loss: 0.5312 - accuracy: 0.7467 - val_loss: 0.7788 - val_accuracy: 0.5676\n",
      "Epoch 52/200\n",
      "1654/1654 [==============================] - 0s 159us/step - loss: 0.4634 - accuracy: 0.7842 - val_loss: 0.7740 - val_accuracy: 0.5797\n",
      "Epoch 53/200\n",
      "1654/1654 [==============================] - 0s 172us/step - loss: 0.4642 - accuracy: 0.7944 - val_loss: 0.7874 - val_accuracy: 0.5845\n",
      "Epoch 54/200\n",
      "1654/1654 [==============================] - 0s 166us/step - loss: 0.4493 - accuracy: 0.7956 - val_loss: 0.8078 - val_accuracy: 0.5725\n",
      "Epoch 55/200\n",
      "1654/1654 [==============================] - 0s 158us/step - loss: 0.4590 - accuracy: 0.7854 - val_loss: 0.8883 - val_accuracy: 0.5556\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1654/1654 [==============================] - 0s 156us/step - loss: 0.4873 - accuracy: 0.7527 - val_loss: 0.8367 - val_accuracy: 0.5628\n",
      "Epoch 57/200\n",
      "1654/1654 [==============================] - 0s 157us/step - loss: 0.4281 - accuracy: 0.8168 - val_loss: 0.8525 - val_accuracy: 0.5652\n",
      "Epoch 58/200\n",
      "1654/1654 [==============================] - 0s 154us/step - loss: 0.4265 - accuracy: 0.8180 - val_loss: 0.8561 - val_accuracy: 0.5628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1da81530f88>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    batch_size=1200,\n",
    "    epochs=200,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "_uuid": "0db183049b59d96388812a98efedfc865b7cc141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 83 114]\n",
      " [ 35 133]]\n",
      "365/365 [==============================] - 0s 421us/step\n",
      "Test set\n",
      "  Loss: 0.871\n",
      "  Accuracy: 0.592\n"
     ]
    }
   ],
   "source": [
    "pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "print(confusion_matrix(Y_test, pred))\n",
    "\n",
    "accr = model.evaluate(X_test, Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
